{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate images for both human eyes and in silico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import function as df\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import os\n",
    "import bz2\n",
    "import math\n",
    "import pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE      = ['SAMPLE','sample_ID']\n",
    "CNV_CHR     = ['chr', 'CHR', 'CHROMOSOME', 'chromosome']\n",
    "CNV_START   = ['cnv_start', 'start', 'PRED_START', 'START']\n",
    "CNV_END     = ['cnv_stop', 'stop', 'PRED_END', 'END']\n",
    "CNV_TYPE    = ['cnv_type','type','TYPE','CNV', 'CNV_TYPE']\n",
    "NUM_TARGETS = ['NUM_TARGETS','targets']\n",
    "CNV_LABEL   = ['LABEL_VAL','label','LABEL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_true_file  = '/home/rt2776/cnv_espresso/training_set/training_set_true.txt'\n",
    "training_set_false_file = '/home/rt2776/cnv_espresso/training_set/training_set_false.txt'\n",
    "RD_norm_dir             = '/home/rt2776/cnv_espresso/data/norm/'\n",
    "ref_samples_dir         = '/home/rt2776/cnv_espresso/reference_samples/'\n",
    "output_false_image_dir  = '/home/rt2776/cnv_espresso/images/false/'\n",
    "output_true_image_dir   = '/home/rt2776/cnv_espresso/images/true/'\n",
    "output_false_image_splits_dir  = '/home/rt2776/cnv_espresso/images/false/splits/'\n",
    "output_true_image_splits_dir   = '/home/rt2776/cnv_espresso/images/true/splits/'\n",
    "\n",
    "target_group = 3 # the number of targets per group\n",
    "color_del = (0,1,0) #green\n",
    "color_dup = (1,0,0) #red\n",
    "\n",
    "if not os.path.exists(output_false_image_dir):\n",
    "        os.makedirs(output_false_image_dir)\n",
    "if not os.path.exists(output_true_image_dir):\n",
    "        os.makedirs(output_true_image_dir)\n",
    "if not os.path.exists(output_false_image_splits_dir):\n",
    "        os.makedirs(output_false_image_splits_dir)\n",
    "if not os.path.exists(output_true_image_splits_dir):\n",
    "        os.makedirs(output_true_image_splits_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loadNormRD(RD_norm_dir, sampleID):\n",
    "#     RD_norm_file = RD_norm_dir+sampleID+'.cov.bed.norm.gz'\n",
    "#     RD_norm_data = pd.read_table(RD_norm_file,low_memory=False,header=None,\n",
    "#                              names=['chr', 'start', 'end', 'GC', 'RD_raw', 'RD_norm'])\n",
    "#     return RD_norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetchRDdata(RD_data, cnv_chr, beginPos, endPos, target_group):\n",
    "#     RD_fetched_data = RD_data[(RD_data[\"chr\"] == str(cnv_chr)) & (RD_data[\"start\"] >= beginPos) & (RD_data[\"end\"] <= endPos)]\n",
    "#     # add a new column as target groups\n",
    "#     RD_fetched_data_tmp = RD_fetched_data.copy()\n",
    "#     RD_fetched_data_tmp.loc[:, 'target_group'] = [val for val in np.arange(1,math.ceil((len(RD_fetched_data_tmp)/target_group))+1) for i in range(target_group)][0:len(RD_fetched_data_tmp)]\n",
    "#     RD_fetched_data = RD_fetched_data_tmp\n",
    "#     del RD_fetched_data_tmp\n",
    "#     return RD_fetched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchRDdata_byTabix(RD_norm_dir, sampleID, cnv_chr, cnv_start, cnv_end, target_group):\n",
    "    # tabix RD file to fetch \n",
    "    RD_norm_file = RD_norm_dir+sampleID+'.cov.bed.norm.gz'\n",
    "    \n",
    "    if not os.path.exists(RD_norm_dir):\n",
    "        print('No tabular file: %s'%RD_norm_file)\n",
    "        return [\"No tabular file\"]\n",
    "    if not os.path.exists(RD_norm_file+'.tbi'):\n",
    "        pysam.tabix_index(RD_norm_file, seq_col=0, start_col=1, end_col=2) # Need to add '-p bed'\n",
    "    \n",
    "    # fetch\n",
    "    f = pysam.TabixFile(RD_norm_file)\n",
    "    RD_fetched_data = f.fetch(cnv_chr, int(cnv_start), int(cnv_end), parser=pysam.asTuple())\n",
    "    RD_fetched_df = pd.DataFrame(data=RD_fetched_data, columns=['chr', 'start', 'end', 'GC', 'RD_raw', 'RD_norm'])\n",
    "    \n",
    "    # add a new column as target groups\n",
    "    RD_fetched_df_tmp = RD_fetched_df.copy()\n",
    "    RD_fetched_df_tmp.loc[:, 'target_group'] = [val for val in np.arange(1,math.ceil((len(RD_fetched_df_tmp)/target_group))+1) for i in range(target_group)][0:len(RD_fetched_df_tmp)]\n",
    "    RD_fetched_df = RD_fetched_df_tmp\n",
    "    del RD_fetched_df_tmp\n",
    "    \n",
    "    # change the type of columns\n",
    "    RD_fetched_df[[\"start\"]] = RD_fetched_df[[\"start\"]].astype(int)\n",
    "    RD_fetched_df[[\"end\"]] = RD_fetched_df[[\"end\"]].astype(int)\n",
    "    RD_fetched_df[[\"GC\"]] = RD_fetched_df[[\"GC\"]].astype(float)\n",
    "    RD_fetched_df[[\"RD_raw\"]] = RD_fetched_df[[\"RD_raw\"]].astype(float)\n",
    "    RD_fetched_df[[\"RD_norm\"]] = RD_fetched_df[[\"RD_norm\"]].astype(float)\n",
    "    \n",
    "    return RD_fetched_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRefSamplesID(ref_samples_file):\n",
    "    ref_samplesID_df = pd.read_table(ref_samples_file,low_memory=False,header=None, sep=' ', \\\n",
    "                             names=['sampleID', 'r2'])\n",
    "    return ref_samplesID_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchRefRDdata_byTabix(ref_samples_file, cnv_chr, cnv_start, cnv_end, target_group):\n",
    "    # load reference sample ID\n",
    "    ref_samplesID_df = loadRefSamplesID(ref_samples_file)\n",
    "      \n",
    "    # load RD normalized data and fetch RD given the cnv region for each reference sample\n",
    "    reference_RD_df = pd.DataFrame(columns=['chr', 'start', 'end', 'GC', 'RD_raw', 'RD_norm', 'sample'])\n",
    "    for index, row in ref_samplesID_df.iterrows():  \n",
    "        ref_sampleID = row[0]\n",
    "        ref_RD_cnv_region = fetchRDdata_byTabix(RD_norm_dir, ref_sampleID, cnv_chr, cnv_start, cnv_end, target_group)\n",
    "        # add a new column as sampleID\n",
    "        RD_cnv_region_tmp = ref_RD_cnv_region.copy()\n",
    "        RD_cnv_region_tmp.loc[:, 'sample'] = [ref_sampleID]*len(ref_RD_cnv_region)\n",
    "        ref_RD_cnv_region = RD_cnv_region_tmp\n",
    "        del RD_cnv_region_tmp\n",
    "        # combine results\n",
    "        reference_RD_df = reference_RD_df.append(ref_RD_cnv_region)\n",
    "        \n",
    "    return reference_RD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_colName(keyWord_list, colName_list):\n",
    "    for keyWord in keyWord_list:\n",
    "        if keyWord in colName_list:\n",
    "            return keyWord\n",
    "        else:\n",
    "            keyWord = None\n",
    "    return keyWord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNV info\n",
    "cnv_data_df = pd.read_table(training_set_true_file, header=0)\n",
    "#cnv_data_df = pd.read_table(training_set_false_file, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHR</th>\n",
       "      <th>PRED_START</th>\n",
       "      <th>PRED_END</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>CANOES_RT</th>\n",
       "      <th>CLAMMS_RT</th>\n",
       "      <th>XHMM_RT</th>\n",
       "      <th>NUM_OVERLAPS_RT</th>\n",
       "      <th>RD_PROP_RT</th>\n",
       "      <th>GC</th>\n",
       "      <th>PRED_SIZE</th>\n",
       "      <th>MAP</th>\n",
       "      <th>NUM_TARGETS</th>\n",
       "      <th>SIZE_LABEL</th>\n",
       "      <th>LABEL_VAL</th>\n",
       "      <th>ref</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1450683</td>\n",
       "      <td>1512690</td>\n",
       "      <td>DEL</td>\n",
       "      <td>SP0000027</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.57</td>\n",
       "      <td>62007</td>\n",
       "      <td>0.93</td>\n",
       "      <td>32</td>\n",
       "      <td>F)50KB-75KB</td>\n",
       "      <td>1</td>\n",
       "      <td>hg38</td>\n",
       "      <td>spark1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>46120329</td>\n",
       "      <td>46124649</td>\n",
       "      <td>DEL</td>\n",
       "      <td>SP0000027</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4320</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>B)1KB-5KB</td>\n",
       "      <td>1</td>\n",
       "      <td>hg38</td>\n",
       "      <td>spark1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>95835289</td>\n",
       "      <td>95923954</td>\n",
       "      <td>DUP</td>\n",
       "      <td>SP0000027</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.36</td>\n",
       "      <td>88665</td>\n",
       "      <td>0.99</td>\n",
       "      <td>17</td>\n",
       "      <td>G)75KB-100KB</td>\n",
       "      <td>1</td>\n",
       "      <td>hg38</td>\n",
       "      <td>spark1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>7869862</td>\n",
       "      <td>7936037</td>\n",
       "      <td>DUP</td>\n",
       "      <td>SP0000027</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.46</td>\n",
       "      <td>66175</td>\n",
       "      <td>0.98</td>\n",
       "      <td>17</td>\n",
       "      <td>F)50KB-75KB</td>\n",
       "      <td>1</td>\n",
       "      <td>hg38</td>\n",
       "      <td>spark1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>32517738</td>\n",
       "      <td>32589742</td>\n",
       "      <td>DUP</td>\n",
       "      <td>SP0000027</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.42</td>\n",
       "      <td>72004</td>\n",
       "      <td>0.99</td>\n",
       "      <td>12</td>\n",
       "      <td>F)50KB-75KB</td>\n",
       "      <td>1</td>\n",
       "      <td>hg38</td>\n",
       "      <td>spark1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58850</th>\n",
       "      <td>19</td>\n",
       "      <td>51643354</td>\n",
       "      <td>51645530</td>\n",
       "      <td>DEL</td>\n",
       "      <td>SP0154427</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.54</td>\n",
       "      <td>2176</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>B)1KB-5KB</td>\n",
       "      <td>1</td>\n",
       "      <td>hg38</td>\n",
       "      <td>spark10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58851</th>\n",
       "      <td>1</td>\n",
       "      <td>39738900</td>\n",
       "      <td>39844640</td>\n",
       "      <td>DUP</td>\n",
       "      <td>SP0154427</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.49</td>\n",
       "      <td>105740</td>\n",
       "      <td>0.96</td>\n",
       "      <td>25</td>\n",
       "      <td>H)100KB-250KB</td>\n",
       "      <td>1</td>\n",
       "      <td>hg38</td>\n",
       "      <td>spark10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58852</th>\n",
       "      <td>3</td>\n",
       "      <td>113249802</td>\n",
       "      <td>113273341</td>\n",
       "      <td>DUP</td>\n",
       "      <td>SP0154427</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.47</td>\n",
       "      <td>23539</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>D)10KB-25KB</td>\n",
       "      <td>1</td>\n",
       "      <td>hg38</td>\n",
       "      <td>spark10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58853</th>\n",
       "      <td>16</td>\n",
       "      <td>28823259</td>\n",
       "      <td>28990012</td>\n",
       "      <td>DUP</td>\n",
       "      <td>SP0154427</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.52</td>\n",
       "      <td>166753</td>\n",
       "      <td>1.00</td>\n",
       "      <td>127</td>\n",
       "      <td>H)100KB-250KB</td>\n",
       "      <td>1</td>\n",
       "      <td>hg38</td>\n",
       "      <td>spark10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58854</th>\n",
       "      <td>16</td>\n",
       "      <td>55810516</td>\n",
       "      <td>55833055</td>\n",
       "      <td>DUP</td>\n",
       "      <td>SP0154427</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.49</td>\n",
       "      <td>22539</td>\n",
       "      <td>0.93</td>\n",
       "      <td>11</td>\n",
       "      <td>D)10KB-25KB</td>\n",
       "      <td>1</td>\n",
       "      <td>hg38</td>\n",
       "      <td>spark10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58855 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CHR  PRED_START   PRED_END TYPE     SAMPLE  CANOES_RT  CLAMMS_RT  \\\n",
       "0        1     1450683    1512690  DEL  SP0000027       0.73       0.73   \n",
       "1       19    46120329   46124649  DEL  SP0000027       0.00       1.00   \n",
       "2       11    95835289   95923954  DUP  SP0000027       0.89       0.00   \n",
       "3       12     7869862    7936037  DUP  SP0000027       0.99       1.00   \n",
       "4        6    32517738   32589742  DUP  SP0000027       0.00       0.00   \n",
       "...    ...         ...        ...  ...        ...        ...        ...   \n",
       "58850   19    51643354   51645530  DEL  SP0154427       0.00       1.00   \n",
       "58851    1    39738900   39844640  DUP  SP0154427       1.00       1.00   \n",
       "58852    3   113249802  113273341  DUP  SP0154427       1.00       1.00   \n",
       "58853   16    28823259   28990012  DUP  SP0154427       1.00       0.99   \n",
       "58854   16    55810516   55833055  DUP  SP0154427       0.00       0.40   \n",
       "\n",
       "       XHMM_RT  NUM_OVERLAPS_RT  RD_PROP_RT    GC  PRED_SIZE   MAP  \\\n",
       "0         1.00                3        0.65  0.57      62007  0.93   \n",
       "1         0.00                1        0.64  0.38       4320  1.00   \n",
       "2         1.00                2        2.04  0.36      88665  0.99   \n",
       "3         0.99                3        0.57  0.46      66175  0.98   \n",
       "4         1.00                1        1.19  0.42      72004  0.99   \n",
       "...        ...              ...         ...   ...        ...   ...   \n",
       "58850     1.00                2        0.32  0.54       2176  1.00   \n",
       "58851     1.00                3        2.06  0.49     105740  0.96   \n",
       "58852     1.00                3        2.08  0.47      23539  1.00   \n",
       "58853     1.00                3        0.85  0.52     166753  1.00   \n",
       "58854     1.00                2        1.40  0.49      22539  0.93   \n",
       "\n",
       "       NUM_TARGETS     SIZE_LABEL  LABEL_VAL   ref    batch  \n",
       "0               32    F)50KB-75KB          1  hg38   spark1  \n",
       "1                4      B)1KB-5KB          1  hg38   spark1  \n",
       "2               17   G)75KB-100KB          1  hg38   spark1  \n",
       "3               17    F)50KB-75KB          1  hg38   spark1  \n",
       "4               12    F)50KB-75KB          1  hg38   spark1  \n",
       "...            ...            ...        ...   ...      ...  \n",
       "58850            4      B)1KB-5KB          1  hg38  spark10  \n",
       "58851           25  H)100KB-250KB          1  hg38  spark10  \n",
       "58852            6    D)10KB-25KB          1  hg38  spark10  \n",
       "58853          127  H)100KB-250KB          1  hg38  spark10  \n",
       "58854           11    D)10KB-25KB          1  hg38  spark10  \n",
       "\n",
       "[58855 rows x 18 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnv_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse header\n",
    "cnv_data_header = cnv_data_df.columns.tolist()\n",
    "col_sampleID  = cnv_data_header.index(fetch_colName(cnv_data_header,SAMPLE))\n",
    "col_cnv_chr   = cnv_data_header.index(fetch_colName(cnv_data_header,CNV_CHR))\n",
    "col_cnv_start = cnv_data_header.index(fetch_colName(cnv_data_header,CNV_START))\n",
    "col_cnv_end   = cnv_data_header.index(fetch_colName(cnv_data_header,CNV_END))\n",
    "col_cnv_type  = cnv_data_header.index(fetch_colName(cnv_data_header,CNV_TYPE))\n",
    "col_cnv_num_targets = cnv_data_header.index(fetch_colName(cnv_data_header,NUM_TARGETS))\n",
    "col_cnv_label = cnv_data_header.index(fetch_colName(cnv_data_header,CNV_LABEL))\n",
    "col_cnv_canoes= cnv_data_header.index(fetch_colName(cnv_data_header,['CANOES','CANOES_RT']))\n",
    "col_cnv_xhmm  = cnv_data_header.index(fetch_colName(cnv_data_header,['XHMM','XHMM_RT']))\n",
    "col_cnv_clamms= cnv_data_header.index(fetch_colName(cnv_data_header,['CLAMMS','CLAMMS_RT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in cnv_data_df.iterrows(): \n",
    "#     row = next(cnv_data_df.iterrows())[1]\n",
    "#     index = 1\n",
    "    if index < 119:\n",
    "        continue\n",
    "    sampleID  = row[col_sampleID]\n",
    "    cnv_chr   = row[col_cnv_chr]\n",
    "    cnv_start = np.int(row[col_cnv_start])\n",
    "    cnv_end   = np.int(row[col_cnv_end])\n",
    "    cnv_type  = row[col_cnv_type]\n",
    "    cnv_num_targets = row[col_cnv_num_targets]\n",
    "    cnv_label  = row[col_cnv_label]\n",
    "    cnv_canoes = str(row[col_cnv_canoes])\n",
    "    cnv_xhmm   = str(row[col_cnv_xhmm])\n",
    "    cnv_clamms = str(row[col_cnv_clamms])\n",
    "    case_sample_color = color_del if cnv_type == 'DEL' else color_dup\n",
    "    \n",
    "    if cnv_label == 0:\n",
    "        output_image_dir = output_false_image_dir\n",
    "        output_image_splits_dir = output_false_image_splits_dir\n",
    "    elif cnv_label == 1: \n",
    "        output_image_dir = output_true_image_dir\n",
    "        output_image_splits_dir = output_true_image_splits_dir\n",
    "    else:\n",
    "        print(\"cnv_label error?\", cnv_label)\n",
    "        pdb.set_trace()\n",
    "        \n",
    "    cnv_label_str = \"True\" if cnv_label == 1 else \"False\"\n",
    "    print(\"[%d|%d] Illustrating: %s %s:%d-%d %s #targets:%d Label:%s\"% \\\n",
    "          (len(cnv_data_df), index+1, sampleID, cnv_chr, cnv_start, cnv_end, cnv_type, cnv_num_targets, cnv_label_str))\n",
    "\n",
    "    ## Import RD data info\n",
    "    print(\"  --Step1. Fetching %d capture windows based on CNV boundary ...\"%len(RD_cnv_region))\n",
    "    RD_cnv_region = fetchRDdata_byTabix(RD_norm_dir, sampleID, cnv_chr, cnv_start, cnv_end, target_group)\n",
    "    \n",
    "    ## Fetch Read depth data for reference samples in terms of CNV boundary       \n",
    "    print(\"  --Step2. Fetching RD data for reference samples ...\")\n",
    "    ref_samples_file = ref_samples_dir+sampleID+'.ref.samples.txt.bz2'\n",
    "    if not os.path.exists(ref_samples_file):\n",
    "        print(\"    -[Error]: error in reference samples related file for %s in %s\"%(sampleID, ref_samples_dir))\n",
    "        #TODO: write to log file\n",
    "        continue\n",
    "    reference_RD_df = fetchRefRDdata_byTabix(ref_samples_file, cnv_chr, cnv_start, cnv_end, target_group)\n",
    "        \n",
    "    ## plot whole cnv\n",
    "    print(\"  --Step3. Illustrating an image for the whole CNV ...\")\n",
    "    title_info = sampleID+\" \"+str(cnv_chr)+\":\"+str(cnv_start)+\"-\"+str(cnv_end)+\" \"+cnv_type +\" \"+ str((cnv_end-cnv_start)/1000) + 'kb'+ \\\n",
    "                \" #targets:\"+str(cnv_num_targets) + \" #wins:\" + str(len(RD_cnv_region)) + \"\\nCANOES:\"+cnv_canoes + \" XHMM:\"+cnv_xhmm + \" CLAMMS:\"+cnv_clamms\n",
    "    image_file = str(index+1)+\"_\"+sampleID+\"_\"+str(cnv_chr)+\"_\"+str(cnv_start)+\"_\"+str(cnv_end)+\"_\"+cnv_type+ \"_\"+str(cnv_num_targets)+\"tgs_\"+str(len(RD_cnv_region)) +\"wins.png\"\n",
    "    fig = plt.figure(dpi=150,figsize=(10, 7)) \n",
    "    ax_rd = fig.subplots(nrows=1, ncols=1)\n",
    "    ### plot reference samples\n",
    "    for sample_reader in reference_RD_df[\"sample\"].unique():\n",
    "                ref_sample_df = reference_RD_df[reference_RD_df[\"sample\"]==sample_reader]\n",
    "                ax_rd.plot((ref_sample_df[\"start\"]+ref_sample_df[\"end\"])/2, ref_sample_df[\"RD_norm\"], color='grey', marker='.', linewidth=0.2)\n",
    "    ### plot case sample\n",
    "    ax_rd.plot((RD_cnv_region[\"start\"]+RD_cnv_region[\"end\"])/2, RD_cnv_region[\"RD_norm\"],color=case_sample_color , marker='o', linewidth=2)\n",
    "    ax_rd.set_title(title_info)\n",
    "    plt.savefig(output_image_dir+image_file)\n",
    "    plt.close() \n",
    "    \n",
    "    ## plot split CNV for each three targets\n",
    "    print(\"  --Step4. Illustrating images for the CNV splited by each %d windows ...\"%target_group)\n",
    "    for group_id in np.unique(RD_cnv_region['target_group']):\n",
    "        ## if targets equal to required number (3 by default)\n",
    "        if len(RD_cnv_region[RD_cnv_region['target_group']==group_id]) == target_group:\n",
    "            title_split_info = title_info +\" Group:\"+ str(int(len(RD_cnv_region)/target_group))+\"-\"+ str(group_id)\n",
    "            image_split_file = str(index+1)+\"_\"+sampleID+\"_\"+str(cnv_chr)+\"_\"+str(cnv_start)+\"_\"+str(cnv_end)+\"_\"+cnv_type+ \"_\"+str(cnv_num_targets)+ \\\n",
    "                                \"tgs_\"+str(len(RD_cnv_region)) +\"wins_splits\"+str(int(len(RD_cnv_region)/target_group))+\"_\"+ str(group_id) +\".png\"\n",
    "            fig = plt.figure(dpi=150,figsize=(7, 7)) \n",
    "            ax_rd = fig.subplots(nrows=1, ncols=1)\n",
    "\n",
    "            RD_cnv_region_split = RD_cnv_region[RD_cnv_region[\"target_group\"]==group_id]\n",
    "            reference_RD_df_split = reference_RD_df[reference_RD_df[\"target_group\"]==group_id]\n",
    "            # plot reference samples\n",
    "            for sample_reader in reference_RD_df_split[\"sample\"].unique():\n",
    "                ref_sample_df = reference_RD_df_split[reference_RD_df_split[\"sample\"]==sample_reader]\n",
    "                ax_rd.plot((ref_sample_df[\"start\"]+ref_sample_df[\"end\"])/2, ref_sample_df[\"RD_norm\"], color = 'grey', marker='.', linewidth=0.2)\n",
    "            # plot case sample\n",
    "            ax_rd.plot((RD_cnv_region_split[\"start\"]+RD_cnv_region_split[\"end\"])/2, RD_cnv_region_split[\"RD_norm\"], color=case_sample_color, marker='o', linewidth=2)\n",
    "            ax_rd.set_title(title_split_info)\n",
    "            plt.savefig(output_image_splits_dir+image_split_file)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook generate_images.ipynb to script\n",
      "[NbConvertApp] Writing 14221 bytes to generate_images.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script generate_images.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seaborn version\n",
    "# for index, row in cnv_data_df.iterrows(): \n",
    "#     if index > 1:\n",
    "#         break\n",
    "#     sampleID  = row[col_sampleID]\n",
    "#     cnv_chr   = row[col_cnv_chr]\n",
    "#     cnv_start = np.int(row[col_cnv_start])\n",
    "#     cnv_end   = np.int(row[col_cnv_end])\n",
    "#     cnv_type  = row[col_cnv_type]\n",
    "#     cnv_num_targets = row[col_cnv_num_targets]\n",
    "#     cnv_label = row[col_cnv_label]\n",
    "#     if cnv_label == 0:\n",
    "#         output_image_dir = output_false_image_dir\n",
    "#     elif cnv_label == 1: \n",
    "#         output_image_dir = output_true_image_dir\n",
    "#     else:\n",
    "#         print(\"cnv_label error?\", cnv_label)\n",
    "#         pdb.set_trace()\n",
    "        \n",
    "#     print(\"Illustrating: \", index+1,\"_____\", sampleID, cnv_chr, cnv_start, cnv_end, cnv_type,cnv_num_targets)\n",
    "    \n",
    "#     ## Import RD data info\n",
    "#     RD_norm_data = loadNormRD(RD_norm_dir, sampleID)\n",
    "#     print(\"[Step1] Loaded normalized RD for %s, there are %d #windows of RD signal.\"%(sampleID, len(RD_norm_data)))\n",
    "\n",
    "#     ## Fetch Read depth data for case sample in terms of CNV boundary\n",
    "#     RD_cnv_region = fetchRDdata(RD_norm_data, cnv_chr, cnv_start, cnv_end, target_group)\n",
    "#     print(\"[Step2] Fetched %d capture windows based on CNV boundary.\"%len(RD_cnv_region))\n",
    "    \n",
    "#     ## Fetch Read depth data for reference samples in terms of CNV boundary\n",
    "#     reference_RD_df = fetchRefRDdata(ref_samples_dir, sampleID, cnv_chr, cnv_start, cnv_end, target_group)\n",
    "#     print(\"[Step3] Fetched RD data for reference samples.\")\n",
    "\n",
    "#     ## Generate images\n",
    "#     title_info = sampleID+\" \"+str(cnv_chr)+\":\"+str(cnv_start)+\"-\"+str(cnv_end)+\" \"+cnv_type+ \" #targets:\"+str(cnv_num_targets)\n",
    "#     image_file = str(index+1)+\"_\"+sampleID+\"_\"+str(cnv_chr)+\"_\"+str(cnv_start)+\"_\"+str(cnv_end)+\"_\"+cnv_type+ \"_\"+str(cnv_num_targets)+\"tgs.png\"\n",
    "#     plt.figure(dpi=200,figsize=(10, 7)) \n",
    "#     sns.set_theme(style=\"darkgrid\")\n",
    "#     sns.lineplot(data=reference_RD_df, x=(reference_RD_df[\"start\"]+reference_RD_df[\"end\"])/2, \n",
    "#                  y=\"RD_norm\", units=\"sample\",color=\".7\", estimator=None, marker='.', linewidth=1)\n",
    "#     sns.lineplot(data=RD_cnv_region, x=(RD_cnv_region[\"start\"]+RD_cnv_region[\"end\"])/2, \n",
    "#                  y=\"RD_norm\", marker='o', linewidth=2).set_title(title_info)\n",
    "#     plt.savefig(output_image_dir+image_file)\n",
    "#     print(title_info)\n",
    "#     plt.close()\n",
    "#     print(\"______________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

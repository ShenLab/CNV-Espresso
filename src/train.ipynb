{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNV-espresso training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "import timeit\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.preprocessing\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend\n",
    "\n",
    "import function_dl as func_dl\n",
    "import function as func\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "physical_devices\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/path/to/project'\n",
    "output_model_dir = project_dir + '/train/'\n",
    "\n",
    "batch_size = 32\n",
    "epochs     = 20\n",
    "\n",
    "true_del_file  = project_dir + '/train/true_del.list'\n",
    "true_dup_file  = project_dir + '/train/true_dup.list'\n",
    "false_del_file = project_dir + '/train/false_del.list'\n",
    "false_dup_file = project_dir + '/train/false_dup.list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "seed = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## For rare CNVs\n",
    "true_del_df  = pd.read_csv(true_del_file,  header=0,sep='\\t')\n",
    "false_del_df = pd.read_csv(false_del_file, header=0,sep='\\t')\n",
    "\n",
    "true_dup_df  = pd.read_csv(true_dup_file,  header=0,sep='\\t')\n",
    "false_dup_df = pd.read_csv(false_dup_file, header=0,sep='\\t')\n",
    "\n",
    "true_del_images_path_list  = true_del_df['img_path']\n",
    "false_del_images_path_list = false_del_df['img_path']\n",
    "\n",
    "true_dup_images_path_list  = true_dup_df['img_path']\n",
    "false_dup_images_path_list = false_dup_df['img_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print(\"The shape of each type:\")\n",
    "print(\"True  DEL:\", true_del_images_path_list.shape)\n",
    "print(\"True  DUP:\", true_dup_images_path_list.shape)\n",
    "print(\"False DEL:\", false_del_images_path_list.shape)\n",
    "print(\"False DUP:\", false_dup_images_path_list.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# # entire cnv\n",
    "true_del_img_np = func_dl.loadImgs(true_del_images_path_list, img_width, img_height)\n",
    "true_del_img_np.shape\n",
    "\n",
    "false_del_img_np = func_dl.loadImgs(false_del_images_path_list, img_width, img_height)\n",
    "false_del_img_np.shape\n",
    "\n",
    "true_dup_img_np = func_dl.loadImgs(true_dup_images_path_list, img_width, img_height)\n",
    "true_dup_img_np.shape\n",
    "\n",
    "false_dup_img_np = func_dl.loadImgs(false_dup_images_path_list, img_width, img_height)\n",
    "false_dup_img_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three classes\n",
    "true_del_label = [0 for i in range(0,len(true_del_img_np))]\n",
    "false_del_label = [1 for i in range(0,len(false_del_img_np))]\n",
    "\n",
    "true_dup_label = [2 for i in range(0,len(true_dup_img_np))]\n",
    "false_dup_label = [1 for i in range(0,len(false_dup_img_np))]\n",
    "\n",
    "print(true_del_label[0:5], false_del_label[0:5], true_dup_label[0:5], false_dup_label[0:5])\n",
    "print(len(true_del_label), len(false_del_label), len(true_dup_label), len(false_dup_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cnv_info_df = true_del_df.append(false_del_df, ignore_index=True)\n",
    "combined_cnv_info_df = combined_cnv_info_df.append(true_dup_df, ignore_index=True)\n",
    "combined_cnv_info_df = combined_cnv_info_df.append(false_dup_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_img = np.vstack((true_del_img_np, false_del_img_np, true_dup_img_np, false_dup_img_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_label = true_del_label + false_del_label + true_dup_label + false_dup_label\n",
    "len(combined_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup or restore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Backup\n",
    "backup_path = project_dir +'/train/data_backup/'\n",
    "os.makedirs(backup_path, exist_ok=True)\n",
    "\n",
    "project_name = 'TBD'\n",
    "combined_cnv_info_df.to_csv(backup_path+'rare_cnv_info.csv')\n",
    "np.save(backup_path+'rare_cnv_img', combined_img)\n",
    "np.save(backup_path+'rare_cnv_label_'+str(len(np.unique(combined_label)))+'classes', combined_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_path = project_dir +'/train/data_backup/'\n",
    "project_name = 'TBD'\n",
    "nClasses = 3\n",
    "combined_img = np.load(backup_path + project_name + '_img.npy')\n",
    "combined_label = np.load(backup_path+'rare_cnv_label_'+str(nClasses)+'classes'+ '.npy')\n",
    "combined_cnv_info_df = pd.read_csv(backup_path+project_name+'_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Project: '%s' dataset loaded.\"%project_name)\n",
    "print(\"  -- Shape of image array: \", combined_img.shape)\n",
    "print(\"  -- Shape of label      : \", len(combined_label))\n",
    "try:\n",
    "    print(\"  -- Shape of CNV info   : \", combined_cnv_info_df.shape)\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the shape of input images and create the variable input_shape\n",
    "nRows,nCols,nDims = combined_img.shape[1:]\n",
    "input_shape = (nRows, nCols, nDims)\n",
    "print(\"The shape of input tensor:\",input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to float datatype\n",
    "combined_img = combined_img.astype('float32')\n",
    "\n",
    "# Scale the data to lie between 0 to 1\n",
    "combined_img /= 255\n",
    "\n",
    "# Change the labels from integer to categorical data\n",
    "combined_label_one_hot = to_categorical(combined_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers of training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(combined_label)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)\n",
    "print(\"3 classes label: 0-True deletion; 1-Diploid (False del & False dup); 2-True duplication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's randomly check one CNV image\n",
    "item = random.randint(0,len(combined_label))\n",
    "print(\"Label:\", combined_label[item])\n",
    "func_dl.showImg(combined_img[item])\n",
    "print(combined_img[item][100][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the convolutional neural networks\n",
    "\n",
    "### Split dataset into training (80%) and test (20%) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split image arrays\n",
    "train_img, test_img, train_label, test_label, train_cnv_info_df, test_cnv_info_df = train_test_split(combined_img,\n",
    "                                                                                                    combined_label_one_hot,\n",
    "                                                                                                    combined_cnv_info_df,\n",
    "                                                                                                    test_size=0.2,\n",
    "                                                                                                    shuffle=True,\n",
    "                                                                                                    random_state=seed)\n",
    "\n",
    "train_img, val_img, train_label, val_label, train_cnv_info_df, val_cnv_info_df = train_test_split(train_img,\n",
    "                                                                                                  train_label,\n",
    "                                                                                                  train_cnv_info_df,\n",
    "                                                                                                  test_size=0.25,\n",
    "                                                                                                  shuffle=True,\n",
    "                                                                                                  random_state=seed) # 0.25*0.8=0.2\n",
    "\n",
    "combined_img.shape, train_img.shape, val_img.shape, test_img.shape\n",
    "combined_label_one_hot.shape, train_label.shape, val_label.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN (Transfer learning and fine-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the pretrained MobileNet v1 architecture\n",
    "- Firstly, we keep all the weights of base model frozen to train the FC layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='MobileNet_v1_fine_tuning'\n",
    "base_model = tf.keras.applications.MobileNet(\n",
    "                                weights='imagenet', # Load weights pre-trained model.\n",
    "                                input_shape=(224, 224, 3),  \n",
    "                                include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False\n",
    "inputs = keras.Input(shape=(224, 224, 3)) \n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(nClasses,activation='softmax')(x)\n",
    "model   = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', func_dl.f1_m, func_dl.precision_m, func_dl.recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Training by MobileNet_v1 model ...\")\n",
    "\n",
    "model_file = output_model_dir + project_name + \"_\" + model_name + \"_\" + str(nClasses) + \"classes.h5\"\n",
    "\n",
    "es = EarlyStopping(monitor  ='val_loss', mode='min', verbose=1, patience=3)\n",
    "mc = ModelCheckpoint(model_file,\n",
    "                     monitor='val_accuracy',\n",
    "                     mode   ='max', \n",
    "                     verbose=1, \n",
    "                     save_best_only=True)\n",
    "\n",
    "history = model.fit(train_img, train_label,\n",
    "                    batch_size = batch_size, \n",
    "                    epochs =epochs,\n",
    "                    verbose=1, \n",
    "                    validation_data=(val_img, val_label), \n",
    "                    callbacks=[es, mc])\n",
    "\n",
    "print(\"\\n\")\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(test_img, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "func_dl.draw_loss_accuracy_curves(history, project_name)\n",
    "func_dl.confusion_matrix(model, test_img, test_label, nClasses)\n",
    "fpr, tpr, thresholds, auc = func_dl.pred_roc_data(model, test_img, test_label)\n",
    "func_dl.draw_single_roc_curve(tpr, fpr, auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "- Secondly, Once your model has converged on our train data, we unfreeze all or part of the base model and retrain the whole model end-to-end with a very low learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fine tuning by MobileNet_v1 model ...\")\n",
    "model_file = output_model_dir + project_name + \"_\" + model_name + \"_\" + str(nClasses) + \"classes.h5\"\n",
    "\n",
    "base_model.trainable=True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-5),\n",
    "    loss='categorical_crossentropy', metrics=['accuracy', func_dl.f1_m, func_dl.precision_m, func_dl.recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "mc = ModelCheckpoint(model_file,\n",
    "                     monitor='val_accuracy',\n",
    "                     mode   ='max', \n",
    "                     verbose=1, \n",
    "                     save_best_only=True)\n",
    "\n",
    "history = model.fit(train_img, train_label,\n",
    "                    batch_size = batch_size, \n",
    "                    epochs  = epochs,\n",
    "                    verbose = 1, \n",
    "                    validation_data = (val_img, val_label), \n",
    "                    callbacks = [es, mc])\n",
    "print(\"\\n\")\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(test_img, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "func_dl.draw_loss_accuracy_curves(history, project_name)\n",
    "func_dl.confusion_matrix(model, test_img, test_label, nClasses)\n",
    "fpr, tpr, thresholds, auc = func_dl.pred_roc_data(model, test_img, test_label)\n",
    "func_dl.draw_single_roc_curve(tpr, fpr, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.showDateTime()\n",
    "print(\"[Done]. Please check the trained model at\",model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "462px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 357,
   "position": {
    "height": "40px",
    "left": "1356px",
    "right": "20px",
    "top": "120px",
    "width": "362px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
